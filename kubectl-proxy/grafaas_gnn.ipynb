{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftpmEVwI31z0",
        "outputId": "285d5f3a-4459-4dbd-873d-5f9512929d49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Password:\n",
            "sudo: a password is required\n",
            "zsh:1: command not found: apt-get\n",
            "zsh:1: command not found: pip\n",
            "zsh:1: command not found: pip\n",
            "zsh:1: command not found: pip\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install graphviz\n",
        "!apt-get install -y graphviz libgraphviz-dev pkg-config\n",
        "\n",
        "!pip install pygraphviz\n",
        "!pip install torch torchvision torchaudio torch-geometric\n",
        "!pip install networkx numpy scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rbeMR4nc32ZS",
        "outputId": "5e03f521-ef3d-42a4-d853-066bdef7d394"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pygraphviz'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpygraphviz\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpgv\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pygraphviz'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pygraphviz as pgv\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data, Dataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. dot 파일 읽기 및 그래프 생성\n",
        "def read_dot_file(dot_file_path: str) -> nx.DiGraph:\n",
        "    A = pgv.AGraph(dot_file_path)\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    for node in A.nodes():\n",
        "        G.add_node(node, label=A.get_node(node).attr['label'])\n",
        "\n",
        "    for edge in A.edges():\n",
        "        G.add_edge(edge[0], edge[1], label=A.get_edge(edge[0], edge[1]).attr['label'])\n",
        "\n",
        "    return G\n",
        "\n",
        "\n",
        "# 2. 그래프를 PyTorch Geometric 데이터 형식으로 변환\n",
        "def convert_graph_to_data(G: nx.DiGraph, label: int) -> Data:\n",
        "    edge_index = []\n",
        "    node_labels = []\n",
        "\n",
        "    for node in G.nodes():\n",
        "        node_labels.append(G.nodes[node]['label'])\n",
        "\n",
        "    # 노드 레이블을 레이블 인코딩\n",
        "    label_encoder = LabelEncoder()\n",
        "    node_labels_encoded = label_encoder.fit_transform(node_labels)\n",
        "\n",
        "    for edge in G.edges():\n",
        "        edge_index.append((list(G.nodes()).index(edge[0]), list(G.nodes()).index(edge[1])))\n",
        "\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "    x = torch.tensor(node_labels_encoded, dtype=torch.float).view(-1, 1)  # 노드 특성을 숫자 인코딩으로 설정\n",
        "    data = Data(x=x, edge_index=edge_index)\n",
        "    data.y = torch.tensor([label], dtype=torch.long)  # 그래프 레이블 추가\n",
        "    return data\n",
        "\n",
        "\n",
        "# 3. GNN 모델 정의 (Dropout과 Batch Normalization 추가)\n",
        "class EnhancedGNNModel(torch.nn.Module):\n",
        "    def __init__(self, num_node_features: int):\n",
        "        super(EnhancedGNNModel, self).__init__()\n",
        "        self.conv1 = GCNConv(num_node_features, 32)\n",
        "        self.conv2 = GCNConv(32, 64)\n",
        "        self.conv3 = GCNConv(64, 64)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.batch_norm1 = nn.BatchNorm1d(32)\n",
        "        self.batch_norm2 = nn.BatchNorm1d(64)\n",
        "        self.fc = torch.nn.Linear(64, 2)  # Output for two classes: normal and abnormal\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.batch_norm1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.batch_norm2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = global_mean_pool(x, batch)  # Global pooling for graph-level classification\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# 4. 데이터셋 정의\n",
        "class GraphDataset(Dataset):\n",
        "    def __init__(self, graphs: list, labels: list):\n",
        "        super(GraphDataset, self).__init__()\n",
        "        self.graphs = graphs\n",
        "        self.labels = labels\n",
        "\n",
        "    def len(self) -> int:\n",
        "        return len(self.graphs)\n",
        "\n",
        "    def get(self, idx: int) -> Data:\n",
        "        return self.graphs[idx]\n",
        "\n",
        "\n",
        "# 5. 훈련 과정\n",
        "def train(model: EnhancedGNNModel, data_loader: DataLoader, optimizer: torch.optim.Optimizer) -> None:\n",
        "    model.train()\n",
        "    for data in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = F.nll_loss(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "# 6. 테스트 함수 (F1-score 및 혼동 행렬 저장)\n",
        "def test(model: EnhancedGNNModel, data_loader: DataLoader) -> (float, float):\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in data_loader:\n",
        "            out = model(data)\n",
        "            pred = out.argmax(dim=1)\n",
        "            y_true.extend(data.y.tolist())\n",
        "            y_pred.extend(pred.tolist())\n",
        "\n",
        "    # F1 Score와 Accuracy 계산\n",
        "    f1 = f1_score(y_true, y_pred, average=\"binary\")\n",
        "    accuracy = np.mean(np.array(y_true) == np.array(y_pred))\n",
        "\n",
        "    # 혼동 행렬 저장 및 표시\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Normal\", \"Abnormal\"])\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.savefig(\"confusion_matrix.png\")  # 혼동 행렬을 파일로 저장\n",
        "    plt.show()\n",
        "\n",
        "    return f1, accuracy\n",
        "\n",
        "\n",
        "# 7. 메인 함수\n",
        "def main(normal_dot_files: list, abnormal_dot_files: list) -> None:\n",
        "    # 정상 및 비정상 그래프 로드\n",
        "    normal_graphs = [convert_graph_to_data(read_dot_file(fp), label=0) for fp in normal_dot_files]\n",
        "    abnormal_graphs = [convert_graph_to_data(read_dot_file(fp), label=1) for fp in abnormal_dot_files]\n",
        "\n",
        "    # 정상 및 비정상 그래프 각각을 80:20 비율로 분할\n",
        "    train_normal_graphs, test_normal_graphs = train_test_split(normal_graphs, test_size=0.1, random_state=42)\n",
        "    train_abnormal_graphs, test_abnormal_graphs = train_test_split(abnormal_graphs, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 학습 및 테스트 세트 결합\n",
        "    train_graphs = train_normal_graphs + train_abnormal_graphs\n",
        "    test_graphs = test_normal_graphs + test_abnormal_graphs\n",
        "    train_labels = [0] * len(train_normal_graphs) + [1] * len(train_abnormal_graphs)\n",
        "    test_labels = [0] * len(test_normal_graphs) + [1] * len(test_abnormal_graphs)\n",
        "\n",
        "    # PyTorch Geometric 데이터셋 생성\n",
        "    train_dataset = GraphDataset(train_graphs, train_labels)\n",
        "    test_dataset = GraphDataset(test_graphs, test_labels)\n",
        "\n",
        "    # DataLoader 정의\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "    # 모델 초기화 및 옵티마이저 설정\n",
        "    model = EnhancedGNNModel(num_node_features=1)  # 노드 특성 수 설정\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "    # 모델 학습\n",
        "    for epoch in range(200):  # 에포크 수\n",
        "        train(model, train_loader, optimizer)\n",
        "\n",
        "    # 테스트 데이터셋으로 성능 평가\n",
        "    test_f1, test_accuracy = test(model, test_loader)\n",
        "    print(f\"Overall Test F1 Score: {test_f1:.4f}\")\n",
        "    print(f\"Overall Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "    # F1 Score와 Accuracy 시각화\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.bar(['F1 Score', 'Accuracy'], [test_f1, test_accuracy], color=['blue', 'green'])\n",
        "    plt.title(\"Test F1 Score and Accuracy\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.show()\n",
        "\n",
        "# 8. 실행\n",
        "normal_dot_files = [f\"./graphs/graphs_benign_dot/system_call_graph_{i}.dot\" for i in range(1, 188)]  # 정상 그래프 경로\n",
        "abnormal_dot_files = (\n",
        "    [f\"./graphs/graphs_helloworld_dot/system_call_graph_{i}.dot\" for i in range(1, 201)] +\n",
        "    [f\"./graphs/graphs_sqldump_dot/system_call_graph_{i}.dot\" for i in range(1, 201)] # 비정상 그래프 경로\n",
        ")\n",
        "\n",
        "main(normal_dot_files, abnormal_dot_files)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
